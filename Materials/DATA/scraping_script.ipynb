{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping IMDB User Reviews\n",
    "- To answer how Americans felt about Barbie vs. Oppenhiemer, we decided the first step was to scrape and collect user reviews from the popular movie rating website IMDB.\n",
    "\n",
    "### In this build:\n",
    "- Requirements:\n",
    "    - Selenium `pip install selenium`\n",
    "    - Pandas `pip install pandas`\n",
    "- Links to User Reviews\n",
    "    - [Oppenhiemer](https://www.imdb.com/title/tt15398776/reviews)\n",
    "    - [Barbie](https://www.imdb.com/title/tt1517268/reviews)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By  # Import By\n",
    "\n",
    "PATH = r\"PATH_TO_DRIVER\" # Update to the path of your WebDriver\n",
    "def scrape_reviews(url):\n",
    "    # Setup WebDriver (Ensure you have the correct path to your WebDriver)\n",
    "    service = Service(PATH)  # You need to pass the PATH to your Service\n",
    "    options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    # Wait for the page to load\n",
    "    driver.implicitly_wait(5)\n",
    "    page = 1\n",
    "\n",
    "    # We want at least 1000 review, so get 50 at a safe number\n",
    "    while page < 50:  \n",
    "        try:\n",
    "            # Find the load more button on the webpage\n",
    "            load_more = driver.find_element(By.ID, 'load-more-trigger')  \n",
    "            # Click on that button\n",
    "            load_more.click()\n",
    "            page += 1\n",
    "        except:\n",
    "            # If couldn't find any more button to click, stop\n",
    "            break\n",
    "\n",
    "    # Find and iterate over each review\n",
    "    review = driver.find_elements(By.CLASS_NAME, 'review-container')  # Update to use By.CLASS_NAME\n",
    "    # Set list for each element:\n",
    "    review_x =[]\n",
    "    # Run for loop to get \n",
    "    for n in range(0, len(review)-1):\n",
    "        try:\n",
    "            review_x_tmp = review[n].text\n",
    "            review_x.append(review_x_tmp)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "    return review_x\n",
    "\n",
    "# URLs for \"Barbie\" and \"Oppenheimer\" reviews\n",
    "barbie_reviews_url = 'https://www.imdb.com/title/tt15398776/reviews' \n",
    "oppenheimer_reviews_url = 'https://www.imdb.com/title/tt1517268/reviews'\n",
    "\n",
    "# Scrape reviews for each movie and save to CSV\n",
    "oppenheimer_reviews = scrape_reviews(barbie_reviews_url)\n",
    "barbie_reviews = scrape_reviews(oppenheimer_reviews_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date, and review text from oppenheimer_reviews and barbie_reviews\n",
    "def create_df(reviews):\n",
    "    reviews_df = pd.DataFrame(reviews, columns=['review'])\n",
    "    reviews_df['score'] = reviews_df['review'].apply(lambda x: x.split('\\n')[0])\n",
    "    reviews_df['title'] = reviews_df['review'].apply(lambda x: x.split('\\n')[1])\n",
    "    reviews_df['date'] = reviews_df['review'].apply(lambda x: ' '.join(x.split('\\n')[2].split(' ')[-2:]))\n",
    "    reviews_df['text'] = reviews_df['review'].apply(lambda x: ' '.join(x.split('\\n')[3:4]))\n",
    "    reviews_df.drop(columns=['review'], inplace=True)\n",
    "    return reviews_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(reviews_df):\n",
    "    reviews_df['date'] = pd.to_datetime(reviews_df['date'], errors='coerce')\n",
    "    reviews_df['date'] = reviews_df['date'].dt.strftime('%m %Y')\n",
    "    reviews_df = reviews_df.dropna(subset=['date'])\n",
    "    reviews_df = reviews_df[(reviews_df['date'] >= '07 2023') & (reviews_df['date'] < '10 2023')]\n",
    "    return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "oppenheimer_reviews_df = create_df(oppenheimer_reviews)\n",
    "barbie_reviews_df = create_df(barbie_reviews)\n",
    "\n",
    "oppenheimer_reviews_df = filter_date(oppenheimer_reviews_df)\n",
    "barbie_reviews_df = filter_date(barbie_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "oppenheimer_reviews_df.to_csv('../DATA/oppenheimer_reviews.csv', index=False)\n",
    "barbie_reviews_df.to_csv('../DATA/barbie_reviews.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (main, Sep 11 2023, 08:19:27) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bae868eca559e6fdaaf59ca8923d9e779ed5e59c28ce3970bf9171129c96e6a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
